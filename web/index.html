<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <script src="/scripts/dev-env.js"></script>
    <script src="/scripts/http.js"></script>
    <script src="/scripts/index.js"></script>
    <title>Ideational</title>
    <script src="node_modules/@picovoice/porcupine-web-en-worker/dist/iife/index.js"></script>
    <script src="node_modules/@picovoice/web-voice-processor/dist/iife/index.js"></script>
    <script
      type="application/javascript"
      src="https://cdn.jsdelivr.net/npm/vosk-browser@0.0.5/dist/vosk.js"
    ></script>
    <script type="application/javascript">
      let mediaRecorderInstance = null;
      const beep = new Audio("/assets/listening.mp3");
      const fin = new Audio("/assets/finishedListening.mp3");

      function writeMessage(message) {
        console.log(message);
        document.getElementById("status").innerHTML = message;
      }

      function porcupineErrorCallback(error) {
        writeMessage(error);
      }

      // TO DO: sometimes terminator is firing twice!?
      // ------- We could use a timeout for both blueberry and terminator not to double-fire (1500ms seems sensible from how it was behaving)
      function porcupineKeywordCallback(keyword) {
        if (keyword === "Blueberry") {
          beep.play();
          startRecordingIdea();
        }
        if (keyword === "Terminator") {
          fin.play();
          stopRecordingIdea(mediaRecorderInstance);
        }
      }

      async function startPorcupine() {
        const accessKey = localStorage.getItem("picovoice");
        writeMessage("Porcupine is loading. Please wait...");
        try {
          let ppnEn = await PorcupineWebEnWorker.PorcupineWorkerFactory.create(
            accessKey,
            [
              {
                builtin: "Blueberry",
                sensitivity: 1,
              },
              {
                builtin: "Terminator",
                sensitivity: 1,
              },
            ],
            porcupineKeywordCallback,
            porcupineErrorCallback
          );

          writeMessage("Porcupine worker ready!");

          writeMessage(
            "WebVoiceProcessor initializing. Microphone permissions requested ..."
          );
          let webVp = await window.WebVoiceProcessor.WebVoiceProcessor.init({
            engines: [ppnEn],
          });
          writeMessage("WebVoiceProcessor ready and listening!");
        } catch (err) {
          porcupineErrorCallback(err);
          return;
        }
      }

      const handleSuccess = (stream) => {
        const options = { mimeType: "audio/webm" };
        const recordedChunks = [];
        const mediaRecorder = new MediaRecorder(stream, options);

        mediaRecorder.addEventListener("dataavailable", function (e) {
          if (e.data.size > 0) recordedChunks.push(e.data);
        });

        mediaRecorder.addEventListener("stop", async () => {
          console.log("Recording finsished!");
          const player = document.getElementById("player");
          const blob = new Blob(recordedChunks, { type: "audio/webm" });
          player.src = URL.createObjectURL(blob);
          const audioFile = new File([blob], "user_audio.wav", {
            type: "audio/wav",
          });

          const formData = new FormData();
          formData.append("audio_file", audioFile);
          try {
            const res = await authRequest(
              "/ideas/",
              "POST",
              formData,
              "multipart/form-data"
            );
            if (res.status === 201) {
              getIdeas();
            }
          } catch (err) {
            console.log(err);
          }

          mediaRecorderInstance = null;
        });

        return mediaRecorder;
      };

      const startRecordingIdea = () => {
        navigator.mediaDevices
          .getUserMedia({ audio: true, video: false })
          .then(handleSuccess)
          .then((mediaRecorder) => {
            mediaRecorderInstance = mediaRecorder;
            mediaRecorderInstance.start();
          });
      };

      const stopRecordingIdea = (mediaRecorderInstance) => {
        if (mediaRecorderInstance) {
          mediaRecorderInstance.stop();
        }
      };

      async function init() {
        const resultsContainer = document.getElementById("recognition-result");
        const partialContainer = document.getElementById("partial");

        partialContainer.textContent = "Loading...";

        const channel = new MessageChannel();
        const model = await Vosk.createModel(
          "assets/vosk-model-small-en-us-0.15.zip"
        );
        model.registerPort(channel.port1);

        const sampleRate = 48000;

        const recognizer = new model.KaldiRecognizer(sampleRate);
        recognizer.setWords(true);

        recognizer.on("result", (message) => {
          const result = message.result;
          console.log(JSON.stringify(result, null, 2));

          const newSpan = document.createElement("span");
          newSpan.textContent = `${result.text} `;
          resultsContainer.insertBefore(newSpan, partialContainer);
        });
        recognizer.on("partialresult", (message) => {
          const partial = message.result.partial;

          partialContainer.textContent = partial;
        });

        partialContainer.textContent = "Ready";

        const mediaStream = await navigator.mediaDevices.getUserMedia({
          video: false,
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            channelCount: 1,
            sampleRate,
          },
        });

        const audioContext = new AudioContext();
        await audioContext.audioWorklet.addModule(
          "/scripts/recognizer-processor.js"
        );
        const recognizerProcessor = new AudioWorkletNode(
          audioContext,
          "recognizer-processor",
          { channelCount: 1, numberOfInputs: 1, numberOfOutputs: 1 }
        );
        recognizerProcessor.port.postMessage(
          { action: "init", recognizerId: recognizer.id },
          [channel.port2]
        );
        recognizerProcessor.connect(audioContext.destination);

        const source = audioContext.createMediaStreamSource(mediaStream);
        source.connect(recognizerProcessor);
      }

      window.onload = () => {
        init();
      };
    </script>
  </head>
  <body>
    <h1>ideationaly</h1>
    <div id="status"></div>
    <div id="recognition-result"></div>
    <div id="partial"></div>
    <div class="form-container">
      <form onsubmit="login();return false">
        <input type="text" placeholder="Enter Username" required />
        <input type="password" placeholder="Enter Password" required />
        <button type="submit">Login</button>
      </form>
    </div>
    <div id="ideas-list"></div>
    <button onclick="startPorcupine();">Record</button>
    <div id="status"></div>
    <div id="result"></div>
    <audio id="player" controls></audio>
  </body>
</html>
